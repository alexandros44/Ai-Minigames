# Environment Values #

FRAME_RATE = 8

MAP_SIZE = 200
BOARD_SIZE = 10 # TABLE SIZE NxN
DOT_SIZE = MAP_SIZE // BOARD_SIZE

ACTION_SPACE_SIZE = 4

# Q-Learning Values  #

MOVE_PENALTY = 1
INVALID_MOVE_PENALTY = 100
FOOD_REWARD = 10000

OBSERVATION_SPACE_VALUES = (BOARD_SIZE, BOARD_SIZE, 3)

EPISODES = 3_000
REPLAY_MEMORY_SIZE = 50_000
MIN_REPLAY_MEMORY_SIZE = 1_000
MINIBATCH_SIZE = 32

DISCOUNT = 0.998
LEARNING_RATE = 0.001
UPDATE_TARGET_EVERY = 5
MODEL_NAME = '2x256'
MIN_REWARD = -200
MEMORY_FRACTION = 0.20

epsilon = 1
EPSILON_DECAY = 0.99975
MIN_EPSILON = 0.001

AGGREGATE_STATS_EVERY = 200
SHOW_PREVIEW = True
